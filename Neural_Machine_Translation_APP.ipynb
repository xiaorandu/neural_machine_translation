{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, machine translation is performed by using two **deep learning** approaches: a **Recurrent Neural Network (RNN)** and **Transformer**.\n",
        "\n",
        "The anki data for **Chinese Mandarin to English translation** is trained using **sequence-to-sequence models**."
      ],
      "metadata": {
        "id": "w3RZGHr1prBP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## I. Load Packages"
      ],
      "metadata": {
        "id": "beZPwZCQpri2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import unicodedata\n",
        "import re\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import math\n",
        "import random\n",
        "import os\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction, corpus_bleu\n",
        "\n",
        "rnn_encoder, rnn_encoder, transformer_encoder, transformer_decoder = None, None, None, None\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if __name__=='__main__':\n",
        "    print('Using device:', DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJ6cq8yTrsMx",
        "outputId": "ef92f4ca-4071-4c04-c1a0-86257769db37"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## II. Download and Prepare the Data"
      ],
      "metadata": {
        "id": "JEX4bNBVsE2W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Functions"
      ],
      "metadata": {
        "id": "6CPxpHjAseRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "    \"\"\"Normalizes latin chars with accent to their canonical decomposition\"\"\"\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess_sentence_chn(w):\n",
        "  w = re.sub(r'([?.!,。？！，])', r' \\1 ', w)\n",
        "  w = ' '.join([c for c in w])\n",
        "  w = re.sub(r'[\" \"]+', ' ', w)\n",
        "  w = ' '.join( [t if t not in '1234567890`~@#$%^&*()_-+={}[];\\':\"/<>\\\\|' else '' for t in w.split(' ')] )\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w\n",
        "\n",
        "def preprocess_sentence_general(w):\n",
        "    '''\n",
        "    Preprocess the sentence to add the start, end tokens and make them lower-case\n",
        "    '''\n",
        "    w = unicode_to_ascii(w.lower().strip())  # Normalize and lowercase\n",
        "    w = re.sub(r'([?.!,])', r' \\1 ', w)      # Add space around punctuation\n",
        "    w = re.sub(r'[\" \"]+', ' ', w)            # Replace multiple spaces with a single space\n",
        "    w = ' '.join([t if t not in '1234567890`~@#$%^&*()_-+={}[];\\':\"/<>\\\\|' else '' for t in w.split(' ')])  # Remove unwanted characters\n",
        "\n",
        "    w = w.rstrip().strip()                   # Trim any remaining spaces\n",
        "    w = '<start> ' + w + ' <end>'            # Add start and end tokens\n",
        "    return w\n",
        "\n",
        "def preprocess_sentence(w, lang):\n",
        "    assert lang in [\"chn\", \"general\"]\n",
        "    if lang == \"chn\":\n",
        "      w = preprocess_sentence_chn(w)\n",
        "    elif lang == \"general\":\n",
        "      w = preprocess_sentence_general(w)\n",
        "\n",
        "    w = w.rstrip().strip()\n",
        "    return w\n",
        "\n",
        "def pad_sequences(x, max_len):\n",
        "    padded = np.zeros((max_len), dtype=np.int64)\n",
        "    if len(x) > max_len:\n",
        "        padded[:] = x[:max_len]\n",
        "    else:\n",
        "        padded[:len(x)] = x\n",
        "    return padded\n",
        "\n",
        "\n",
        "def preprocess_data_to_tensor(dataframe, src_vocab, trg_vocab, src_lang, trg_lang):\n",
        "    # Vectorize the input and target languages\n",
        "    src_tensor = [[src_vocab.word2idx[s if s in src_vocab.vocab else '<unk>'] for s in es.split(' ')] for es in dataframe[src_lang].values.tolist()]\n",
        "    trg_tensor = [[trg_vocab.word2idx[s if s in trg_vocab.vocab else '<unk>'] for s in eng.split(' ')] for eng in dataframe[trg_lang].values.tolist()]\n",
        "\n",
        "    # Calculate the max_length of input and output tensor for padding\n",
        "    max_length_src, max_length_trg = max(len(t) for t in src_tensor), max(len(t) for t in trg_tensor)\n",
        "    print('max_length_src: {}, max_length_trg: {}'.format(max_length_src, max_length_trg))\n",
        "\n",
        "    # Pad all the sentences in the dataset with the max_length\n",
        "    src_tensor = [pad_sequences(x, max_length_src) for x in src_tensor]\n",
        "    trg_tensor = [pad_sequences(x, max_length_trg) for x in trg_tensor]\n",
        "\n",
        "    return src_tensor, trg_tensor, max_length_src, max_length_trg\n",
        "\n",
        "\n",
        "def train_test_split(src_tensor, trg_tensor):\n",
        "    '''\n",
        "    Create training and test sets.\n",
        "    '''\n",
        "    total_num_examples = len(src_tensor) - int(0.2*len(src_tensor))\n",
        "    src_tensor_train, src_tensor_test = src_tensor[:int(0.75*total_num_examples)], src_tensor[int(0.75*total_num_examples):total_num_examples]\n",
        "    trg_tensor_train, trg_tensor_test = trg_tensor[:int(0.75*total_num_examples)], trg_tensor[int(0.75*total_num_examples):total_num_examples]\n",
        "\n",
        "    return src_tensor_train, src_tensor_test, trg_tensor_train, trg_tensor_test"
      ],
      "metadata": {
        "id": "SdhcYIcnsaP0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation Functions\n",
        "These functions will be used to evaluate both the RNN and Transformer Models."
      ],
      "metadata": {
        "id": "u2UlyLOkz-hi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_reference_candidate(target, pred, trg_vocab):\n",
        "    def _to_token(sentence):\n",
        "        lis = []\n",
        "        for s in sentence[1:]:\n",
        "            x = trg_vocab.idx2word[s]\n",
        "            if x == \"<end>\": break\n",
        "            lis.append(x)\n",
        "        return lis\n",
        "    reference = _to_token(list(target.numpy()))\n",
        "    candidate = _to_token(list(pred.numpy()))\n",
        "    return reference, candidate\n",
        "\n",
        "def compute_bleu_scores(target_tensor_val, target_output, final_output, trg_vocab):\n",
        "    bleu_1 = 0.0\n",
        "    bleu_2 = 0.0\n",
        "    bleu_3 = 0.0\n",
        "    bleu_4 = 0.0\n",
        "\n",
        "    smoother = SmoothingFunction()\n",
        "    save_reference = []\n",
        "    save_candidate = []\n",
        "    for i in range(len(target_tensor_val)):\n",
        "        reference, candidate = get_reference_candidate(target_output[i], final_output[i], trg_vocab)\n",
        "\n",
        "        bleu_1 += sentence_bleu(reference, candidate, weights=(1,), smoothing_function=smoother.method1)\n",
        "        bleu_2 += sentence_bleu(reference, candidate, weights=(1/2, 1/2), smoothing_function=smoother.method1)\n",
        "        bleu_3 += sentence_bleu(reference, candidate, weights=(1/3, 1/3, 1/3), smoothing_function=smoother.method1)\n",
        "        bleu_4 += sentence_bleu(reference, candidate, weights=(1/4, 1/4, 1/4, 1/4), smoothing_function=smoother.method1)\n",
        "\n",
        "        save_reference.append(reference)\n",
        "        save_candidate.append(candidate)\n",
        "\n",
        "    bleu_1 = bleu_1/len(target_tensor_val)\n",
        "    bleu_2 = bleu_2/len(target_tensor_val)\n",
        "    bleu_3 = bleu_3/len(target_tensor_val)\n",
        "    bleu_4 = bleu_4/len(target_tensor_val)\n",
        "\n",
        "    scores = {\"bleu_1\": bleu_1, \"bleu_2\": bleu_2, \"bleu_3\": bleu_3, \"bleu_4\": bleu_4}\n",
        "    print('BLEU 1-gram: %f' % (bleu_1))\n",
        "    print('BLEU 2-gram: %f' % (bleu_2))\n",
        "    print('BLEU 3-gram: %f' % (bleu_3))\n",
        "    print('BLEU 4-gram: %f' % (bleu_4))\n",
        "\n",
        "    return save_candidate, scores"
      ],
      "metadata": {
        "id": "QWIXzB_R0E2L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download and Visualize the Data"
      ],
      "metadata": {
        "id": "zmAS0D2e0LI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lang_path = 'cmn-eng'\n",
        "\n",
        "os.system(f\"wget http://www.manythings.org/anki/{lang_path}.zip\")\n",
        "os.system(f\"unzip -o {lang_path}.zip\")\n",
        "src_script, trg_script = \"chn\", \"general\"\n",
        "src_lang, trg_lang = lang_path.split('-')[0], lang_path.split('-')[1]"
      ],
      "metadata": {
        "id": "Lf2K4BJ9z7JO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_num_examples = 50000\n",
        "dat = pd.read_csv(f'{src_lang}.txt',\n",
        "                sep=\"\\t\",\n",
        "                header=None,\n",
        "                usecols=[0,1],\n",
        "                names=[f'{trg_lang}', f'{src_lang}'],\n",
        "                nrows=total_num_examples,\n",
        "                encoding=\"UTF-8\"\n",
        ").sample(frac=1).reset_index().drop(['index'], axis=1)\n",
        "\n",
        "dat # Visualize the data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "dVy671t601ZA",
        "outputId": "6296cd18-28de-4e37-ffff-d37dc1bfcf12"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     eng              cmn\n",
              "0                         I ate breakfast on my balcony.       我在陽臺上吃的早飯。\n",
              "1                                Tom tried to kill Mary.        汤姆试着杀死玛丽。\n",
              "2                                  This rug is handmade.      这块地毯是手工制作的。\n",
              "3                        The road was wet from the rain.    這條路因為下雨所以是濕的。\n",
              "4                                 Did you open a window?         你打開窗戶了嗎?\n",
              "...                                                  ...              ...\n",
              "29904   The train was delayed because of heavy snowfall.       火车因大雪被耽搁了。\n",
              "29905  Did you check all the items on the shopping list?  你把購物單上的全都檢查過了嗎？\n",
              "29906                   She set out on a trip last week.         她上週去旅行了。\n",
              "29907         I think this machine is in need of repair.      我认为这机器需要修理。\n",
              "29908                    We need to do what's necessary.        我們須做該做的事。\n",
              "\n",
              "[29909 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4dfc1d37-be6d-4ff3-bc28-cf6cd63d6486\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>cmn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I ate breakfast on my balcony.</td>\n",
              "      <td>我在陽臺上吃的早飯。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tom tried to kill Mary.</td>\n",
              "      <td>汤姆试着杀死玛丽。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This rug is handmade.</td>\n",
              "      <td>这块地毯是手工制作的。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The road was wet from the rain.</td>\n",
              "      <td>這條路因為下雨所以是濕的。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Did you open a window?</td>\n",
              "      <td>你打開窗戶了嗎?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29904</th>\n",
              "      <td>The train was delayed because of heavy snowfall.</td>\n",
              "      <td>火车因大雪被耽搁了。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29905</th>\n",
              "      <td>Did you check all the items on the shopping list?</td>\n",
              "      <td>你把購物單上的全都檢查過了嗎？</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29906</th>\n",
              "      <td>She set out on a trip last week.</td>\n",
              "      <td>她上週去旅行了。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29907</th>\n",
              "      <td>I think this machine is in need of repair.</td>\n",
              "      <td>我认为这机器需要修理。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29908</th>\n",
              "      <td>We need to do what's necessary.</td>\n",
              "      <td>我們須做該做的事。</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29909 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4dfc1d37-be6d-4ff3-bc28-cf6cd63d6486')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4dfc1d37-be6d-4ff3-bc28-cf6cd63d6486 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4dfc1d37-be6d-4ff3-bc28-cf6cd63d6486');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8f1084d9-fbc8-437d-a9cb-ecd2c779a62e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8f1084d9-fbc8-437d-a9cb-ecd2c779a62e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8f1084d9-fbc8-437d-a9cb-ecd2c779a62e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_1d860a02-66c5-4b55-9321-3fe6828fc17f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dat')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1d860a02-66c5-4b55-9321-3fe6828fc17f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('dat');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dat",
              "summary": "{\n  \"name\": \"dat\",\n  \"rows\": 29909,\n  \"fields\": [\n    {\n      \"column\": \"eng\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 28329,\n        \"samples\": [\n          \"The exam was divided into two parts.\",\n          \"Thank you for inviting me to dinner.\",\n          \"Tom cares about you.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cmn\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26139,\n        \"samples\": [\n          \"\\u8001\\u4eba\\u4eca\\u5929\\u65e9\\u4e0a\\u53bb\\u4e16\\u4e86\\u3002\",\n          \"\\u6c64\\u59c6\\u53ef\\u80fd\\u60f3\\u8ba9\\u4f60\\u5e2e\\u4ed6\\u3002\",\n          \"\\u9ebb\\u7169\\u62f7\\u8c9d\\u9019\\u500b\\u3002\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess the data"
      ],
      "metadata": {
        "id": "-xwMmPbK3iT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = dat.copy()\n",
        "\n",
        "data[trg_lang] = dat[trg_lang].apply(lambda w: preprocess_sentence(w, trg_script))\n",
        "data[src_lang] = dat[src_lang].apply(lambda w: preprocess_sentence(w, src_script))\n",
        "data # Visualizing the data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "xvl70n0k3luh",
        "outputId": "7ca502c2-2099-415c-d374-2930f6b7e42a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     eng  \\\n",
              "0          <start> i ate breakfast on my balcony . <end>   \n",
              "1                 <start> tom tried to kill mary . <end>   \n",
              "2                   <start> this rug is handmade . <end>   \n",
              "3         <start> the road was wet from the rain . <end>   \n",
              "4                  <start> did you open a window ? <end>   \n",
              "...                                                  ...   \n",
              "29904  <start> the train was delayed because of heavy...   \n",
              "29905  <start> did you check all the items on the sho...   \n",
              "29906    <start> she set out on a trip last week . <end>   \n",
              "29907  <start> i think this machine is in need of rep...   \n",
              "29908     <start> we need to do what's necessary . <end>   \n",
              "\n",
              "                                               cmn  \n",
              "0                <start> 我 在 陽 臺 上 吃 的 早 飯 。 <end>  \n",
              "1                  <start> 汤 姆 试 着 杀 死 玛 丽 。 <end>  \n",
              "2              <start> 这 块 地 毯 是 手 工 制 作 的 。 <end>  \n",
              "3          <start> 這 條 路 因 為 下 雨 所 以 是 濕 的 。 <end>  \n",
              "4                    <start> 你 打 開 窗 戶 了 嗎 ? <end>  \n",
              "...                                            ...  \n",
              "29904            <start> 火 车 因 大 雪 被 耽 搁 了 。 <end>  \n",
              "29905  <start> 你 把 購 物 單 上 的 全 都 檢 查 過 了 嗎 ？ <end>  \n",
              "29906                <start> 她 上 週 去 旅 行 了 。 <end>  \n",
              "29907          <start> 我 认 为 这 机 器 需 要 修 理 。 <end>  \n",
              "29908              <start> 我 們 須 做 該 做 的 事 。 <end>  \n",
              "\n",
              "[29909 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0bb24dcf-bcfd-4a1f-b70c-3b9f8bc2d9c8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>cmn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;start&gt; i ate breakfast on my balcony . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; 我 在 陽 臺 上 吃 的 早 飯 。 &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;start&gt; tom tried to kill mary . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; 汤 姆 试 着 杀 死 玛 丽 。 &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;start&gt; this rug is handmade . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; 这 块 地 毯 是 手 工 制 作 的 。 &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;start&gt; the road was wet from the rain . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; 這 條 路 因 為 下 雨 所 以 是 濕 的 。 &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;start&gt; did you open a window ? &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; 你 打 開 窗 戶 了 嗎 ? &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29904</th>\n",
              "      <td>&lt;start&gt; the train was delayed because of heavy...</td>\n",
              "      <td>&lt;start&gt; 火 车 因 大 雪 被 耽 搁 了 。 &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29905</th>\n",
              "      <td>&lt;start&gt; did you check all the items on the sho...</td>\n",
              "      <td>&lt;start&gt; 你 把 購 物 單 上 的 全 都 檢 查 過 了 嗎 ？ &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29906</th>\n",
              "      <td>&lt;start&gt; she set out on a trip last week . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; 她 上 週 去 旅 行 了 。 &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29907</th>\n",
              "      <td>&lt;start&gt; i think this machine is in need of rep...</td>\n",
              "      <td>&lt;start&gt; 我 认 为 这 机 器 需 要 修 理 。 &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29908</th>\n",
              "      <td>&lt;start&gt; we need to do what's necessary . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; 我 們 須 做 該 做 的 事 。 &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29909 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0bb24dcf-bcfd-4a1f-b70c-3b9f8bc2d9c8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0bb24dcf-bcfd-4a1f-b70c-3b9f8bc2d9c8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0bb24dcf-bcfd-4a1f-b70c-3b9f8bc2d9c8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4d8310b0-f38c-4280-bb0c-b7259c333cbd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4d8310b0-f38c-4280-bb0c-b7259c333cbd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4d8310b0-f38c-4280-bb0c-b7259c333cbd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_43526e7f-9233-4168-b61f-3d51bcf06df8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_43526e7f-9233-4168-b61f-3d51bcf06df8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 29909,\n  \"fields\": [\n    {\n      \"column\": \"eng\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 28329,\n        \"samples\": [\n          \"<start> the exam was divided into two parts . <end>\",\n          \"<start> thank you for inviting me to dinner . <end>\",\n          \"<start> tom cares about you . <end>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cmn\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26139,\n        \"samples\": [\n          \"<start> \\u8001 \\u4eba \\u4eca \\u5929 \\u65e9 \\u4e0a \\u53bb \\u4e16 \\u4e86 \\u3002 <end>\",\n          \"<start> \\u6c64 \\u59c6 \\u53ef \\u80fd \\u60f3 \\u8ba9 \\u4f60 \\u5e2e \\u4ed6 \\u3002 <end>\",\n          \"<start> \\u9ebb \\u7169 \\u62f7 \\u8c9d \\u9019 \\u500b \\u3002 <end>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vocabulary & Dataloader Classes"
      ],
      "metadata": {
        "id": "lzvRdENS_78l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A class fro managing the vocabulary is created. There is a seperate class for the vocabulary because there are two dfiferent vacabularies - one for source language and one for target language.\n",
        "\n",
        "Then the dataloader is prepared and return the source sentence and target sentence."
      ],
      "metadata": {
        "id": "xvneuLLVCa1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocab_Lang():\n",
        "    def __init__(self, vocab):\n",
        "        self.word2idx = {'<pad>': 0, '<unk>': 1}\n",
        "        self.idx2word = {0: '<pad>', 1: '<unk>'}\n",
        "        self.vocab = vocab\n",
        "\n",
        "        for index, word in enumerate(vocab):\n",
        "            self.word2idx[word] = index + 2 # +2 because of <pad> and <unk> token\n",
        "            self.idx2word[index + 2] = word\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.word2idx)\n",
        "\n",
        "    def __repr__(self):\n",
        "        if len(self.vocab) <= 5:\n",
        "            return str(self.vocab)\n",
        "        else:\n",
        "            return f'Vocab_Lang object with {len(self.vocab)} words'\n",
        "\n",
        "class MyData(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.length = torch.LongTensor([np.sum(1 - np.equal(x, 0)) for x in X])\n",
        "        self.data = torch.LongTensor(X)\n",
        "        self.target = torch.LongTensor(y)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "CGEIzYnd__3I"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "SKCxayl3DpLK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adjust hyperparameters\n",
        "BATCH_SIZE = 64\n",
        "EMBEDDING_DIM = 256"
      ],
      "metadata": {
        "id": "8PMNoQRiAHro"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build Vocabulary"
      ],
      "metadata": {
        "id": "O7IugFkzCHwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocabulary(pd_dataframe):\n",
        "    sentences = [sen.split() for sen in pd_dataframe]\n",
        "    vocab = {}\n",
        "    for sen in sentences:\n",
        "        for word in sen:\n",
        "            if word not in vocab:\n",
        "                vocab[word] = 1\n",
        "    return list(vocab.keys())"
      ],
      "metadata": {
        "id": "nivLY8SgCKhf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab_list = build_vocabulary(data[src_lang])\n",
        "trg_vocab_list = build_vocabulary(data[trg_lang])"
      ],
      "metadata": {
        "id": "_KNbk_VcCNX0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instantiate Datasets\n",
        "The train and test datasets are now instantiated."
      ],
      "metadata": {
        "id": "NBm-ScxzC8zb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab = Vocab_Lang(src_vocab_list)\n",
        "trg_vocab = Vocab_Lang(trg_vocab_list)\n",
        "\n",
        "src_tensor, trg_tensor, max_length_src, max_length_trg = preprocess_data_to_tensor(data, src_vocab, trg_vocab, src_lang, trg_lang)\n",
        "src_tensor_train, src_tensor_val, trg_tensor_train, trg_tensor_val = train_test_split(src_tensor, trg_tensor)\n",
        "\n",
        "# create train and val datasets\n",
        "train_dataset = MyData(src_tensor_train, trg_tensor_train)\n",
        "train_dataset = DataLoader(train_dataset, batch_size=BATCH_SIZE, drop_last=True, shuffle=True)\n",
        "\n",
        "test_dataset = MyData(src_tensor_val, trg_tensor_val)\n",
        "test_dataset = DataLoader(test_dataset, batch_size=BATCH_SIZE, drop_last=True, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGzhtQ2RC6LF",
        "outputId": "5bab7bc8-9dab-4c92-9d49-5934a16e6730"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_length_src: 46, max_length_trg: 36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-a7fab9dc3e3b>:23: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  self.data = torch.LongTensor(X)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idxes = random.choices(range(len(train_dataset.dataset)), k=5)\n",
        "src, trg =  train_dataset.dataset[idxes]\n",
        "print('Source:', src)\n",
        "print('Source Dimensions: ', src.size())\n",
        "print('Target:', trg)\n",
        "print('Target Dimensions: ', trg.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OKins0UfDFsc",
        "outputId": "6f994ae1-5a69-4cf3-969c-39044dedee7d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source: tensor([[   2,    3,  152, 1713,   81,   12,   13,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [   2,  260,  263, 1448,  377,  502,   12,   13,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [   2,   41,    4, 1564,   50,   12,   13,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [   2,    3,  153,   41, 1735,   12,   13,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [   2,  101, 1078, 1078,    9,  530,  321,  179,    3,  102,  318,  231,\n",
            "         1161, 1410,   46,   12,   13,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0]])\n",
            "Source Dimensions:  torch.Size([5, 46])\n",
            "Target: tensor([[   2,    3,  114, 1972,    9,   10,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [   2,  228, 3818, 1201, 1503,    9,   10,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [   2,  294, 1386,    9,   10,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [   2,   97, 3551,  116,   27,    9,   10,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [   2,  142, 3408,  135,   93,   48,   78, 2747,    9,   10,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]])\n",
            "Target Dimensions:  torch.Size([5, 36])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QDhM4vBRghgw",
        "outputId": "ccd98d50-e1d1-48a6-a218-4878076aceac"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.41.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.112.0-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.3.0 (from gradio)\n",
            "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.5)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.4)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.8.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.5.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.30.5-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.15.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.20.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-4.41.0-py3-none-any.whl (12.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Downloading ruff-0.5.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.30.5-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.112.0-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, tomlkit, semantic-version, ruff, python-multipart, orjson, h11, ffmpy, aiofiles, uvicorn, starlette, httpcore, httpx, fastapi, gradio-client, gradio\n",
            "  Attempting uninstall: tomlkit\n",
            "    Found existing installation: tomlkit 0.13.0\n",
            "    Uninstalling tomlkit-0.13.0:\n",
            "      Successfully uninstalled tomlkit-0.13.0\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.112.0 ffmpy-0.4.0 gradio-4.41.0 gradio-client-1.3.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 orjson-3.10.7 pydub-0.25.1 python-multipart-0.0.9 ruff-0.5.7 semantic-version-2.10.0 starlette-0.37.2 tomlkit-0.12.0 uvicorn-0.30.5 websockets-12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## III. Encoder and Decoder Models"
      ],
      "metadata": {
        "id": "ofVubsmjj240"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_positional_embedding(max_len, embed_dim):\n",
        "    '''\n",
        "    Args:\n",
        "        max_len: The maximum length supported for positional embeddings\n",
        "        embed_dim: The size of your embeddings\n",
        "    Returns:\n",
        "        pe: [max_len, 1, embed_dim] computed as in the formulae above\n",
        "    '''\n",
        "    pe = torch.zeros(max_len, embed_dim)\n",
        "    pos = torch.arange(0, max_len).unsqueeze(1)\n",
        "    div_term = torch.exp((torch.arange(0, embed_dim, 2, dtype=torch.float) * (-math.log(10000.0) / embed_dim)))\n",
        "    pe[:, 0::2] = torch.sin(pos.float() * div_term)\n",
        "    pe[:, 1::2] = torch.cos(pos.float() * div_term)\n",
        "    pe = pe.unsqueeze(0).transpose(0,1)\n",
        "\n",
        "    return pe"
      ],
      "metadata": {
        "id": "uHl3NG6z3B2E"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder Model\n"
      ],
      "metadata": {
        "id": "wJ_Q2VGeEYcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, src_vocab, embedding_dim, num_heads,\n",
        "        num_layers, dim_feedforward, max_len_src, device, dropout=0.1):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.device = device\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            src_vocab: Vocab_Lang, the source vocabulary\n",
        "            embedding_dim: the dimension of the embedding (also the number of expected features for the input of the Transformer)\n",
        "            num_heads: The number of attention heads\n",
        "            num_layers: the number of Transformer Encoder layers\n",
        "            dim_feedforward: the dimension of the feedforward network models in the Transformer\n",
        "            max_len_src: maximum length of the source sentences\n",
        "            device: the working device (you may need to map your postional embedding to this device)\n",
        "            dropout: the dropout to be applied. Default=0.1.\n",
        "        \"\"\"\n",
        "        self.src_vocab = src_vocab\n",
        "        src_vocab_size = len(src_vocab)\n",
        "\n",
        "        # Create positional embedding matrix\n",
        "        self.position_embedding = create_positional_embedding(max_len_src, embedding_dim).to(device)\n",
        "        self.register_buffer('positional_embedding', self.position_embedding) # this informs the model that position_embedding is not a learnable parameter\n",
        "\n",
        "        # Initialize embedding layer\n",
        "        self.embedding = nn.Embedding(src_vocab_size, embedding_dim)\n",
        "\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout()\n",
        "\n",
        "        # Initialize a nn.TransformerEncoder model (use embedding_dim,\n",
        "        # num_layers, num_heads, & dim_feedforward here)\n",
        "        enc_model = nn.TransformerEncoderLayer(embedding_dim, num_heads, dim_feedforward)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(enc_model, num_layers).to(device)\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            src: [max_len, batch_size]\n",
        "        Returns:\n",
        "            Boolean matrix of size [batch_size, max_len] indicating which indices are padding\n",
        "        \"\"\"\n",
        "        assert len(src.shape) == 2, 'src must have exactly 2 dimensions'\n",
        "        src_mask = src.transpose(0, 1) == 0 # padding idx\n",
        "        return src_mask.to(self.device) # [batch_size, max_src_len]\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: [max_len, batch_size]\n",
        "        Returns:\n",
        "            output: [max_len, batch_size, embed_dim]\n",
        "        Steps (note: x refers to the original input to this function throughout the pseudo-code):\n",
        "        - Pass x through the word embedding\n",
        "        - Add positional embedding to the word embedding, then apply dropout\n",
        "        - Call make_src_mask(x) to compute a mask: this tells us which indexes in x\n",
        "          are padding, which we want to ignore for the self-attention\n",
        "        - Call the encoder, with src_key_padding_mask = src_mask\n",
        "        \"\"\"\n",
        "\n",
        "        embedding = self.embedding(x).to(self.device)\n",
        "        embedding = self.dropout(embedding + self.position_embedding[:embedding.size(0)])\n",
        "        embedding_mask = self.make_src_mask(x)\n",
        "\n",
        "        output = self.transformer_encoder(embedding, src_key_padding_mask=embedding_mask)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "oLLqDTjJFBBb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoder Model\n"
      ],
      "metadata": {
        "id": "7zfNBo6cFs47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, trg_vocab, embedding_dim, num_heads,\n",
        "        num_layers, dim_feedforward, max_len_trg, device, dropout=0.1):\n",
        "        super(TransformerDecoder, self).__init__()\n",
        "        self.device = device\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            trg_vocab: Vocab_Lang, the target vocabulary\n",
        "            embedding_dim: the dimension of the embedding (also the number of expected features for the input of the Transformer)\n",
        "            num_heads: The number of attention heads\n",
        "            num_layers: the number of Transformer Decoder layers\n",
        "            dim_feedforward: the dimension of the feedforward network models in the Transformer\n",
        "            max_len_trg: maximum length of the target sentences\n",
        "            device: the working device\n",
        "            dropout: the dropout to be applied. Default=0.1.\n",
        "        \"\"\"\n",
        "        self.trg_vocab = trg_vocab\n",
        "        trg_vocab_size = len(trg_vocab)\n",
        "\n",
        "        # Create positional embedding matrix\n",
        "        self.position_embedding = create_positional_embedding(max_len_trg, embedding_dim).to(self.device)\n",
        "        self.register_buffer('positional_embedding', self.position_embedding) # this informs the model that positional_embedding is not a learnable parameter\n",
        "\n",
        "        # Initialize embedding layer\n",
        "        self.embedding = nn.Embedding(trg_vocab_size, embedding_dim)\n",
        "\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout()\n",
        "\n",
        "        # Initialize a nn.TransformerDecoder model (you'll need to use embedding_dim,\n",
        "        # num_layers, num_heads, & dim_feedforward here)\n",
        "        decoder_model = nn.TransformerDecoderLayer(embedding_dim, num_heads, dim_feedforward).to(self.device)\n",
        "        self.transfomer_decoder = nn.TransformerDecoder(decoder_model,num_layers)\n",
        "\n",
        "        # Final fully connected layer\n",
        "        self.fc = nn.Linear(embedding_dim,trg_vocab_size)\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        \"\"\"Generate a square mask for the sequence. The masked positions are filled with float('-inf').\n",
        "            Unmasked positions are filled with float(0.0).\n",
        "        \"\"\"\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0)).to(self.device)\n",
        "        return mask\n",
        "\n",
        "    def forward(self, dec_in, enc_out):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            dec_in: [sequence length, batch_size]\n",
        "            enc_out: [max_len, batch_size, embed_dim]\n",
        "        Returns:\n",
        "            output: [sequence length, batch_size, trg_vocab_size]\n",
        "        Steps:\n",
        "        - Compute input word and positional embeddings in similar manner to encoder\n",
        "        - Call generate_square_subsequent_mask() to compute a mask: this time,\n",
        "          the mask is to prevent the decoder from attending to tokens in the \"future\".\n",
        "          In other words, at time step i, the decoder should only attend to tokens\n",
        "          1 to i-1.\n",
        "        - Call the decoder, with tgt_mask = trg_mask\n",
        "        - Run the output through the fully-connected layer and return it\n",
        "        \"\"\"\n",
        "        embedding = self.embedding(dec_in.to(self.device))\n",
        "        embedding = self.dropout(embedding + self.position_embedding[:embedding.size(0)])\n",
        "\n",
        "        trg_mask = self.generate_square_subsequent_mask(dec_in.size(0))\n",
        "        output = self.transfomer_decoder(embedding, enc_out, tgt_mask=trg_mask)\n",
        "\n",
        "        output = self.fc(output)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "w3T--I0gFoOR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IV. Demo Interface"
      ],
      "metadata": {
        "id": "39_Bsn3vjMfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzUIzLj_iYqT",
        "outputId": "50f8f7c3-dadb-4451-bf21-40b1a36cf932"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gradio as gr\n",
        "\n",
        "encoder = torch.load('/content/drive/MyDrive/transformer_encoder_cmn.pt')\n",
        "decoder = torch.load('/content/drive/MyDrive/transformer_decoder_cmn.pt')\n",
        "\n",
        "encoder.to(DEVICE)\n",
        "decoder.to(DEVICE)\n",
        "\n",
        "encoder.eval()\n",
        "decoder.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo6reI0phPIQ",
        "outputId": "c0a2b66a-c270-48c7-ee22-02e4d73a22a2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransformerDecoder(\n",
              "  (embedding): Embedding(7368, 256)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (transfomer_decoder): TransformerDecoder(\n",
              "    (layers): ModuleList(\n",
              "      (0-1): 2 x TransformerDecoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (multihead_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (fc): Linear(in_features=256, out_features=7368, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "def tokenize_input(input_sentence, vocab):\n",
        "    \"\"\"\n",
        "    Tokenize and convert input sentence to indices using the provided vocabulary.\n",
        "    \"\"\"\n",
        "    return [vocab.word2idx.get(char, vocab.word2idx['<unk>']) for char in input_sentence]\n",
        "\n",
        "\n",
        "def detokenize_output(output_indices, vocab):\n",
        "    \"\"\"\n",
        "    Convert output indices to words and remove special tokens.\n",
        "    \"\"\"\n",
        "    words = []\n",
        "    for idx in output_indices:\n",
        "        if idx not in {vocab.word2idx['<pad>'], vocab.word2idx['<start>'], vocab.word2idx['<end>']}:\n",
        "            word = vocab.idx2word.get(idx, '<unk>')\n",
        "            if word == '<unk>':\n",
        "                word = '[UNK]'\n",
        "            words.append(word)\n",
        "    return ' '.join(words)\n",
        "\n",
        "\n",
        "def decode_transformer_model(encoder, decoder, src, max_decode_len, device):\n",
        "    trg_vocab = decoder.trg_vocab\n",
        "    batch_size = src.size(1)\n",
        "    curr_output = torch.zeros((batch_size, max_decode_len), dtype=torch.long).to(device)\n",
        "    curr_predictions = torch.zeros((batch_size, max_decode_len, len(trg_vocab.idx2word))).to(device)\n",
        "\n",
        "    # Start decoding with the start token\n",
        "    dec_input = torch.tensor([[trg_vocab.word2idx['<start>']]] * batch_size, device=device)\n",
        "    curr_output[:, 0] = dec_input.squeeze(1)\n",
        "\n",
        "    # Encoder output\n",
        "    enc_output = encoder(src.to(device))\n",
        "\n",
        "    for t in range(1, max_decode_len):\n",
        "        # Prepare decoder input\n",
        "        dec_in = curr_output[:, :t]\n",
        "\n",
        "        # Ensure the correct dimensions for decoder input\n",
        "        dec_in = dec_in.transpose(0, 1).to(device)\n",
        "\n",
        "        # Decode\n",
        "        predictions = decoder(dec_in, enc_output)\n",
        "\n",
        "        # Extract the last prediction\n",
        "        predictions = predictions[-1, :, :]\n",
        "\n",
        "        # Store predictions\n",
        "        curr_predictions[:, t, :] = predictions\n",
        "\n",
        "        # Get the next token\n",
        "        next_token = torch.argmax(predictions, dim=1)\n",
        "        curr_output[:, t] = next_token\n",
        "\n",
        "        # Break if all sequences have generated the <end> token\n",
        "        if torch.all(next_token == trg_vocab.word2idx['<end>']):\n",
        "            break\n",
        "\n",
        "    return curr_output, curr_predictions, enc_output\n",
        "\n",
        "def translate_sentence(input_sentence):\n",
        "    \"\"\"\n",
        "    Translate an input sentence using the preloaded Transformer model.\n",
        "    \"\"\"\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "\n",
        "    try:\n",
        "        # Tokenize the input sentence\n",
        "        src_indices = tokenize_input(input_sentence, encoder.src_vocab)\n",
        "        src_tensor = torch.tensor(src_indices).unsqueeze(1).to(DEVICE)  # Shape: [max_len, 1]\n",
        "\n",
        "        # Decode the sentence\n",
        "        curr_output, _, _ = decode_transformer_model(encoder, decoder, src_tensor, max_decode_len=50, device=DEVICE)\n",
        "\n",
        "        # Convert output indices to words\n",
        "        translated_sentence = detokenize_output(curr_output.squeeze(0).tolist(), decoder.trg_vocab)\n",
        "\n",
        "        return translated_sentence\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during translation: {str(e)}\")\n",
        "        return str(e)"
      ],
      "metadata": {
        "id": "hTcAaIY_lknG"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "examples = [\n",
        "    [\"你今天在做什么呢？\"],\n",
        "    [\"我今天过得很开心。\"],\n",
        "    [\"我非常喜欢夏天。\"]\n",
        "]\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=translate_sentence,\n",
        "    inputs=gr.Textbox(label=\"Chinese\"),\n",
        "    outputs=gr.Textbox(label=\"English\"),\n",
        "    title=\"Neural Machine Translation App\",\n",
        "    description=\"Enter a sentence in Chinese and get the translation in English.\",\n",
        "    examples=examples\n",
        ")\n",
        "\n",
        "interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "HmmsvVscjAFC",
        "outputId": "54738e2d-410a-4bc9-b191-3239a702abdf"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://516d35b9845ccda268.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://516d35b9845ccda268.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    }
  ]
}